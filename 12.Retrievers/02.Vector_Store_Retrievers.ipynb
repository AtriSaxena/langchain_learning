{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc387bf5",
   "metadata": {},
   "source": [
    "## Vector Store Retrievers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb25a6fd",
   "metadata": {},
   "source": [
    "!pip install langchain chromadb faiss-cpu openai tiktoken langchain_openai langchain-community wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Your source documents\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain helps developers build LLM applications easily.\"),\n",
    "    Document(page_content=\"Chroma is a vector database optimized for LLM-based search.\"),\n",
    "    Document(page_content=\"Embeddings convert text into high-dimensional vectors.\"),\n",
    "    Document(page_content=\"OpenAI provides powerful embedding models.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2709cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize embedding model\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Step 3: Create Chroma vector store in memory\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"my_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41519e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Convert vectorstore into a retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8367b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Chroma used for?\"\n",
    "results = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ed44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.similarity_search(query, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e332765",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d495b79",
   "metadata": {},
   "source": [
    "### MMR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4ead2f",
   "metadata": {},
   "source": [
    "# Sample documents\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain makes it easy to work with LLMs.\"),\n",
    "    Document(page_content=\"LangChain is used to build LLM based applications.\"),\n",
    "    Document(page_content=\"Chroma is used to store and search document embeddings.\"),\n",
    "    Document(page_content=\"Embeddings are vector representations of text.\"),\n",
    "    Document(page_content=\"MMR helps you get diverse results when doing similarity search.\"),\n",
    "    Document(page_content=\"LangChain supports Chroma, FAISS, Pinecone, and more.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c755e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Step 2: Create the FAISS vector store from documents\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6477618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable MMR in the retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",                   # <-- This enables MMR\n",
    "    search_kwargs={\"k\": 3, \"lambda_mult\": 0.5}  # k = top results, lambda_mult = relevance-diversity balance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb995ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is langchain?\"\n",
    "results = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64d070",
   "metadata": {},
   "source": [
    "### Multiquery Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2de02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528188bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant health & wellness documents\n",
    "all_docs = [\n",
    "    Document(page_content=\"Regular walking boosts heart health and can reduce symptoms of depression.\", metadata={\"source\": \"H1\"}),\n",
    "    Document(page_content=\"Consuming leafy greens and fruits helps detox the body and improve longevity.\", metadata={\"source\": \"H2\"}),\n",
    "    Document(page_content=\"Deep sleep is crucial for cellular repair and emotional regulation.\", metadata={\"source\": \"H3\"}),\n",
    "    Document(page_content=\"Mindfulness and controlled breathing lower cortisol and improve mental clarity.\", metadata={\"source\": \"H4\"}),\n",
    "    Document(page_content=\"Drinking sufficient water throughout the day helps maintain metabolism and energy.\", metadata={\"source\": \"H5\"}),\n",
    "    Document(page_content=\"The solar energy system in modern homes helps balance electricity demand.\", metadata={\"source\": \"I1\"}),\n",
    "    Document(page_content=\"Python balances readability with power, making it a popular system design language.\", metadata={\"source\": \"I2\"}),\n",
    "    Document(page_content=\"Photosynthesis enables plants to produce energy by converting sunlight.\", metadata={\"source\": \"I3\"}),\n",
    "    Document(page_content=\"The 2022 FIFA World Cup was held in Qatar and drew global energy and excitement.\", metadata={\"source\": \"I4\"}),\n",
    "    Document(page_content=\"Black holes bend spacetime and store immense gravitational energy.\", metadata={\"source\": \"I5\"}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415cee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI embeddings\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Create FAISS vector store\n",
    "vectorstore = FAISS.from_documents(documents=all_docs, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af4b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retrievers\n",
    "similarity_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f55ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "query = \"How to improve energy levels and maintain balance?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16bc156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve results\n",
    "similarity_results = similarity_retriever.invoke(query)\n",
    "multiquery_results= multiquery_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56fff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(similarity_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)\n",
    "\n",
    "print(\"*\"*150)\n",
    "\n",
    "for i, doc in enumerate(multiquery_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8eb5a5",
   "metadata": {},
   "source": [
    "### ContextualCompressionRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2351cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the document objects from the previous data\n",
    "docs = [\n",
    "    Document(page_content=(\n",
    "        \"\"\"The Grand Canyon is one of the most visited natural wonders in the world.\n",
    "        Photosynthesis is the process by which green plants convert sunlight into energy.\n",
    "        Millions of tourists travel to see it every year. The rocks date back millions of years.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc1\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"In medieval Europe, castles were built primarily for defense.\n",
    "        The chlorophyll in plant cells captures sunlight during photosynthesis.\n",
    "        Knights wore armor made of metal. Siege weapons were often used to breach castle walls.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc2\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"Basketball was invented by Dr. James Naismith in the late 19th century.\n",
    "        It was originally played with a soccer ball and peach baskets. NBA is now a global league.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc3\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"The history of cinema began in the late 1800s. Silent films were the earliest form.\n",
    "        Thomas Edison was among the pioneers. Photosynthesis does not occur in animal cells.\n",
    "        Modern filmmaking involves complex CGI and sound design.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc4\"})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAISS vector store from the documents\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e618ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c40b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the compressor using an LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad87c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the contextual compression retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_retriever=base_retriever,\n",
    "    base_compressor=compressor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c158988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the retriever\n",
    "query = \"What is photosynthesis?\"\n",
    "compressed_results = compression_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fdbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(compressed_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
